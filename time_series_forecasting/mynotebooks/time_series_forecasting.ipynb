{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-Aa4xpN01nEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52addc7-1ccb-435c-e2ba-10745695aa82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARIMA Test MSE: 6506.6721\n",
            "SARIMA Test MSE: 908.3542\n",
            "Holt-Winters Test MSE: 6104.7073\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "df = pd.read_csv(url, index_col='Month', parse_dates=True)\n",
        "\n",
        "# Train/test split\n",
        "train_size = int(len(df) * 0.8)\n",
        "train, test = df[:train_size], df[train_size:]\n",
        "\n",
        "# Models dictionary to store fitted models and forecasts\n",
        "models = {}\n",
        "\n",
        "# --- Model 1: ARIMA ---\n",
        "arima_model = ARIMA(train, order=(5, 1, 0))\n",
        "arima_fit = arima_model.fit()\n",
        "arima_forecast = arima_fit.forecast(steps=len(test))\n",
        "arima_mse = mean_squared_error(test, arima_forecast)\n",
        "models['ARIMA'] = {'model': arima_fit, 'forecast': arima_forecast, 'mse': arima_mse}\n",
        "\n",
        "# --- Model 2: SARIMA ---\n",
        "sarima_model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
        "sarima_fit = sarima_model.fit(disp=False)\n",
        "sarima_forecast = sarima_fit.forecast(steps=len(test))\n",
        "sarima_mse = mean_squared_error(test, sarima_forecast)\n",
        "models['SARIMA'] = {'model': sarima_fit, 'forecast': sarima_forecast, 'mse': sarima_mse}\n",
        "\n",
        "# --- Model 3: Exponential Smoothing (Holt-Winters) ---\n",
        "hw_model = ExponentialSmoothing(train, seasonal='add', seasonal_periods=12)\n",
        "hw_fit = hw_model.fit()\n",
        "hw_forecast = hw_fit.forecast(steps=len(test))\n",
        "hw_mse = mean_squared_error(test, hw_forecast)\n",
        "models['Holt-Winters'] = {'model': hw_fit, 'forecast': hw_forecast, 'mse': hw_mse}\n",
        "\n",
        "# Save all models and forecasts\n",
        "with open('time_series_models.pkl', 'wb') as f:\n",
        "    pickle.dump(models, f)\n",
        "\n",
        "# Plot and save graphs for each model\n",
        "if not os.path.exists('static'):\n",
        "    os.makedirs('static')\n",
        "\n",
        "for model_name, model_info in models.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(test, label='Actual')\n",
        "    plt.plot(model_info['forecast'], label=f'{model_name} Forecast')\n",
        "    plt.title(f'{model_name} Model - Test MSE: {model_info[\"mse\"]:.4f}')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'static/{model_name}_forecast.png')\n",
        "    plt.close()\n",
        "\n",
        "# Print MSE for all models\n",
        "for model_name, model_info in models.items():\n",
        "    print(f'{model_name} Test MSE: {model_info[\"mse\"]:.4f}')\n"
      ]
    }
  ]
}